{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaikaiLiu0104/KaikaiLiu0104-DataScience-GenAI-Submissions/blob/main/Asynchronous%20Tasks%206%20/%206_02_dnn_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1xqQczl0FG-qtNA2_WQYuWePW9oU8irqJ)"
      ],
      "metadata": {
        "id": "E0T9_-jFXxxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.02 Dense Neural Network (with PyTorch)\n",
        "This will expand on our logistic regression example and take us through building our first neural network. If you haven't already, be sure to check (and if neccessary) switch to GPU processing by clicking Runtime > Change runtime type and selecting GPU. We can test this has worked with the following code:"
      ],
      "metadata": {
        "id": "dcEWDwlu94Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"Num GPUs Available: \", torch.cuda.device_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8cIpNbCvuQA",
        "outputId": "2fcb3120-2a02-475b-c5e3-e24db7195f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully your code shows you have 1 GPU available! Next let's get some data. We'll start with another in-built dataset:"
      ],
      "metadata": {
        "id": "8d6FF1wK-ph8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload an in-built Python (OK semi-in-built) dataset\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# import the data\n",
        "data = load_diabetes()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MziWWXu-0ur",
        "outputId": "235ddbf0-7eac-4fde-bd4b-45c4f5d032d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990749, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06833155, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286131, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04688253,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452873, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00422151,  0.00306441]]),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 442\\n\\n:Number of Attributes: First 10 columns are numeric predictive values\\n\\n:Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n:Attribute Information:\\n    - age     age in years\\n    - sex\\n    - bmi     body mass index\\n    - bp      average blood pressure\\n    - s1      tc, total serum cholesterol\\n    - s2      ldl, low-density lipoproteins\\n    - s3      hdl, high-density lipoproteins\\n    - s4      tch, total cholesterol / HDL\\n    - s5      ltg, possibly log of serum triglycerides level\\n    - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'diabetes_data_raw.csv.gz',\n",
              " 'target_filename': 'diabetes_target.csv.gz',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are working on a regression problem, with \"structured\" data which has already been cleaned and normalised. We can skip the usual cleaning/engineering steps. However, we do need to get the data into PyTorch:"
      ],
      "metadata": {
        "id": "cZKrbx70_cIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(data.data, dtype=torch.float32)\n",
        "y = torch.tensor(data.target, dtype=torch.float32).reshape(-1, 1) # Reshape y to be a column vector"
      ],
      "metadata": {
        "id": "f9PHiljr73fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our data is stored in tensors we can do train/test splitting as before (in fact we can use sklearn as before):"
      ],
      "metadata": {
        "id": "hu8VH2_SAOoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYJN01DV8Fac",
        "outputId": "a9669171-67a6-4ae9-beba-cd6534abf571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([353, 10]) torch.Size([353, 1])\n",
            "torch.Size([89, 10]) torch.Size([89, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set up our batches for training. As we have a nice round 400 let's go with batches of 50 (8 batches in total). We'll also seperate the features and labels:"
      ],
      "metadata": {
        "id": "LKmbZoCrJijU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Create TensorDatasets and DataLoaders\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "de0uOko08d-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now its time to build our model. We'll keep it simple ... a model with an input layer of 10 features and then 2x _Dense_ (fully connected) layers each with 5 neurons and ReLU activation. Our output layer will be size=1 given this is a regression problem and we want a single value output per prediction.\n",
        "\n",
        "This will be easier to understand if you have read through the logistic regression tutorial."
      ],
      "metadata": {
        "id": "yCCG8kKHCVnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class DiabetesModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModel, self).__init__()\n",
        "        # we'll set up the layers as a sequence using nn.Sequential\n",
        "        self.layers = nn.Sequential(\n",
        "\n",
        "            # first layer will be a linear layer that has 10x neurons\n",
        "            # (10x sets of linear regression)\n",
        "            # the layer takes the 10 features as input (i.e. 10, 10)\n",
        "            nn.Linear(10, 10),\n",
        "\n",
        "            nn.ReLU(), # ReLU activation\n",
        "\n",
        "            # second linear layer again has 5 neurons\n",
        "            # this time taking the input as the output of the last layer\n",
        "            # (which had 10x neurons)\n",
        "            nn.Linear(10, 5),\n",
        "\n",
        "            nn.ReLU(), # ReLU again\n",
        "\n",
        "            # third linear layer again has 5 neurons\n",
        "            # this time taking the input as the output of the last layer\n",
        "            # (which had 5x neurons)\n",
        "            nn.Linear(5, 5),\n",
        "\n",
        "            nn.ReLU(), # ReLU again\n",
        "\n",
        "            # last linear layer takes the output from the previous 5 neurons\n",
        "            # this time its a single output with no activation\n",
        "            # i.e. this is the predicitons (regression)\n",
        "            nn.Linear(5, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x) # pass the data through the layers"
      ],
      "metadata": {
        "id": "844H60hcCV3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before we need to create a model object, specify the loss (criterion) and an optimiser (which we cover next week):"
      ],
      "metadata": {
        "id": "cv4-loCz91aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = DiabetesModel()\n",
        "criterion = nn.MSELoss() # MSE loss function\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "EPx_Wy6g9uA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train the model. Again, the logistic regression tutorial (6.01) may help you undertstand this:"
      ],
      "metadata": {
        "id": "HOKfjkfW-Ish"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop (example - you'll likely want to add more epochs)\n",
        "epochs = 100 # 100 epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # use the train_loader to pass the inputs (x) and targets (y)\n",
        "  for inputs, targets in train_loader:\n",
        "    # pass to the GPU (hopefully)\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # pass model to GPU as well\n",
        "    model.to(device)\n",
        "\n",
        "    model.train() # put the model object in train mode\n",
        "    optimiser.zero_grad() # reset the gradiants\n",
        "    outputs = model(inputs) # create outputs\n",
        "    loss = criterion(outputs, targets) # compare with Y to get loss\n",
        "    loss.backward() # backpropogate the loss (next week)\n",
        "    optimiser.step() # # update the parameters based on this round of training\n",
        "\n",
        "  # every 10 steps we will print out the current loss\n",
        "    if (epoch+1) % 10 == 0: # modular arithmetic\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {round(loss.item(), 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtMUgfwT-HGt",
        "outputId": "b9c1f921-58b1-4f99-8ac5-db90f710bf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 31355.1074\n",
            "Epoch [10/100], Loss: 37448.9727\n",
            "Epoch [10/100], Loss: 25332.1504\n",
            "Epoch [10/100], Loss: 24448.3613\n",
            "Epoch [10/100], Loss: 34616.0977\n",
            "Epoch [10/100], Loss: 25724.7441\n",
            "Epoch [10/100], Loss: 29233.1289\n",
            "Epoch [10/100], Loss: 39533.9883\n",
            "Epoch [20/100], Loss: 27204.5898\n",
            "Epoch [20/100], Loss: 30760.5801\n",
            "Epoch [20/100], Loss: 32875.8477\n",
            "Epoch [20/100], Loss: 28877.4043\n",
            "Epoch [20/100], Loss: 29146.2793\n",
            "Epoch [20/100], Loss: 32186.6934\n",
            "Epoch [20/100], Loss: 28805.6465\n",
            "Epoch [20/100], Loss: 8335.1895\n",
            "Epoch [30/100], Loss: 32594.1367\n",
            "Epoch [30/100], Loss: 25430.0098\n",
            "Epoch [30/100], Loss: 28704.8848\n",
            "Epoch [30/100], Loss: 28930.6777\n",
            "Epoch [30/100], Loss: 31619.7812\n",
            "Epoch [30/100], Loss: 26475.5039\n",
            "Epoch [30/100], Loss: 35336.4258\n",
            "Epoch [30/100], Loss: 18184.0859\n",
            "Epoch [40/100], Loss: 36775.6953\n",
            "Epoch [40/100], Loss: 25324.541\n",
            "Epoch [40/100], Loss: 32435.6387\n",
            "Epoch [40/100], Loss: 27816.125\n",
            "Epoch [40/100], Loss: 24479.5664\n",
            "Epoch [40/100], Loss: 30774.0684\n",
            "Epoch [40/100], Loss: 30319.3262\n",
            "Epoch [40/100], Loss: 34729.1992\n",
            "Epoch [50/100], Loss: 25028.0547\n",
            "Epoch [50/100], Loss: 32613.8047\n",
            "Epoch [50/100], Loss: 28749.332\n",
            "Epoch [50/100], Loss: 31516.5371\n",
            "Epoch [50/100], Loss: 27096.3691\n",
            "Epoch [50/100], Loss: 33411.7734\n",
            "Epoch [50/100], Loss: 30351.4043\n",
            "Epoch [50/100], Loss: 17837.75\n",
            "Epoch [60/100], Loss: 31324.1113\n",
            "Epoch [60/100], Loss: 31880.1211\n",
            "Epoch [60/100], Loss: 28667.832\n",
            "Epoch [60/100], Loss: 25361.7793\n",
            "Epoch [60/100], Loss: 29755.7051\n",
            "Epoch [60/100], Loss: 27502.3047\n",
            "Epoch [60/100], Loss: 33596.2734\n",
            "Epoch [60/100], Loss: 26336.0781\n",
            "Epoch [70/100], Loss: 28660.3398\n",
            "Epoch [70/100], Loss: 29445.3945\n",
            "Epoch [70/100], Loss: 34068.2031\n",
            "Epoch [70/100], Loss: 29157.1113\n",
            "Epoch [70/100], Loss: 29403.6914\n",
            "Epoch [70/100], Loss: 30555.2988\n",
            "Epoch [70/100], Loss: 26093.0039\n",
            "Epoch [70/100], Loss: 35236.8906\n",
            "Epoch [80/100], Loss: 26871.9395\n",
            "Epoch [80/100], Loss: 31634.7363\n",
            "Epoch [80/100], Loss: 28355.9141\n",
            "Epoch [80/100], Loss: 31585.4922\n",
            "Epoch [80/100], Loss: 30492.5918\n",
            "Epoch [80/100], Loss: 30184.9902\n",
            "Epoch [80/100], Loss: 28175.2695\n",
            "Epoch [80/100], Loss: 33737.9844\n",
            "Epoch [90/100], Loss: 29437.6152\n",
            "Epoch [90/100], Loss: 28352.6348\n",
            "Epoch [90/100], Loss: 24552.4688\n",
            "Epoch [90/100], Loss: 29059.3789\n",
            "Epoch [90/100], Loss: 37245.6641\n",
            "Epoch [90/100], Loss: 31597.5684\n",
            "Epoch [90/100], Loss: 26964.2793\n",
            "Epoch [90/100], Loss: 32425.1055\n",
            "Epoch [100/100], Loss: 26965.7715\n",
            "Epoch [100/100], Loss: 28642.0371\n",
            "Epoch [100/100], Loss: 23528.1543\n",
            "Epoch [100/100], Loss: 28986.6602\n",
            "Epoch [100/100], Loss: 28955.7051\n",
            "Epoch [100/100], Loss: 34584.3398\n",
            "Epoch [100/100], Loss: 35930.7109\n",
            "Epoch [100/100], Loss: 23142.6953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see loss is significantly lower at the end than it was at the start. However, it is also bouncing around a little still which suggests the model needs more training (100 epochs is not a lot in deep learning terms). However, let's evaluate as before:"
      ],
      "metadata": {
        "id": "E72ZTKSqAODE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation (example)\n",
        "model.eval() # testing mode\n",
        "mse_values = [] # collect the MSE scores\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs) # predict the test data\n",
        "\n",
        "        # Calculate Mean Squared Error\n",
        "        mse = criterion(outputs, targets) # calcualte mse for the batch\n",
        "        mse_values.append(mse.item()) # add to the list of MSE values\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse = np.mean(mse_values)\n",
        "print(f\"Average MSE on test set: {avg_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbuAH6p8A-Vh",
        "outputId": "76633061-a20f-484e-ab13-d9e05d6a01e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set: 26078.5205078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE looks expected given training (no obvious sign of overfitting). However, we probably can get better results with tuning and more epochs.\n",
        "\n",
        "Let's run the loop again a little differently to collect the predicted values (y_hat) and actuals (y) and add them to a dataset for comparions:"
      ],
      "metadata": {
        "id": "HQ26bA08Up12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predictions.extend(outputs.cpu().numpy())\n",
        "        actuals.extend(targets.cpu().numpy())\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame({'Predicted': np.array(predictions).flatten(), 'Actual': np.array(actuals).flatten()})\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "8AYsDDSLUp_u",
        "outputId": "fef028b6-6ea9-43b9-db10-8d7ac89277cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Predicted  Actual\n",
              "0     0.36457   219.0\n",
              "1     0.36457    70.0\n",
              "2     0.36457   202.0\n",
              "3     0.36457   230.0\n",
              "4     0.36457   111.0\n",
              "..        ...     ...\n",
              "84    0.36457   153.0\n",
              "85    0.36457    98.0\n",
              "86    0.36457    37.0\n",
              "87    0.36457    63.0\n",
              "88    0.36457   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cff6260-285c-4725-b85d-b061e4dc5972\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0.36457</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cff6260-285c-4725-b85d-b061e4dc5972')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cff6260-285c-4725-b85d-b061e4dc5972 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cff6260-285c-4725-b85d-b061e4dc5972');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2e01f67c-4177-457b-87c7-6be89e780ebf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e01f67c-4177-457b-87c7-6be89e780ebf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2e01f67c-4177-457b-87c7-6be89e780ebf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ec864739-dc47-4fc3-b2f3-f27106feb44e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec864739-dc47-4fc3-b2f3-f27106feb44e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3645702302455902\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Side-by-side, they don't look great. Can you improve them?\n",
        "\n",
        "<br><br>\n",
        "\n",
        "## EXERCISE #1\n",
        "Try increasing the number of epochs to 1,000 (when the model is fairly well trained then the results printed for each 10x epochs will be fairly stable and not change much). Does this give better results?\n",
        "\n",
        "<br><br>\n",
        "\n",
        "## EXERCISE #2 (optional)\n",
        "Try experimenting with the architecture (number of neurons and/or number of layers). Can we reach an optimal architecture?"
      ],
      "metadata": {
        "id": "LDcM98lHbgP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop (example - you'll likely want to add more epochs)\n",
        "epochs = 1000 # 1000 epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # use the train_loader to pass the inputs (x) and targets (y)\n",
        "  for inputs, targets in train_loader:\n",
        "    # pass to the GPU (hopefully)\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # pass model to GPU as well\n",
        "    model.to(device)\n",
        "\n",
        "    model.train() # put the model object in train mode\n",
        "    optimiser.zero_grad() # reset the gradiants\n",
        "    outputs = model(inputs) # create outputs\n",
        "    loss = criterion(outputs, targets) # compare with Y to get loss\n",
        "    loss.backward() # backpropogate the loss (next week)\n",
        "    optimiser.step() # # update the parameters based on this round of training\n",
        "\n",
        "  # every 10 steps we will print out the current loss\n",
        "    if (epoch+1) % 10 == 0: # modular arithmetic\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {round(loss.item(), 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0_ZUqzfAjg4",
        "outputId": "d1014ad0-0f76-4923-b9b8-5ae754808a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Loss: 30549.6797\n",
            "Epoch [10/1000], Loss: 25320.7227\n",
            "Epoch [10/1000], Loss: 33230.5391\n",
            "Epoch [10/1000], Loss: 24167.3945\n",
            "Epoch [10/1000], Loss: 28846.0703\n",
            "Epoch [10/1000], Loss: 30293.7461\n",
            "Epoch [10/1000], Loss: 35246.1797\n",
            "Epoch [10/1000], Loss: 19266.4961\n",
            "Epoch [20/1000], Loss: 35031.0195\n",
            "Epoch [20/1000], Loss: 24190.834\n",
            "Epoch [20/1000], Loss: 29560.459\n",
            "Epoch [20/1000], Loss: 30734.3398\n",
            "Epoch [20/1000], Loss: 28277.834\n",
            "Epoch [20/1000], Loss: 27783.7598\n",
            "Epoch [20/1000], Loss: 31926.6309\n",
            "Epoch [20/1000], Loss: 18917.0156\n",
            "Epoch [30/1000], Loss: 30283.125\n",
            "Epoch [30/1000], Loss: 37553.3281\n",
            "Epoch [30/1000], Loss: 32335.377\n",
            "Epoch [30/1000], Loss: 25629.2969\n",
            "Epoch [30/1000], Loss: 26547.4199\n",
            "Epoch [30/1000], Loss: 25467.2051\n",
            "Epoch [30/1000], Loss: 30067.0234\n",
            "Epoch [30/1000], Loss: 9781.7227\n",
            "Epoch [40/1000], Loss: 30442.8242\n",
            "Epoch [40/1000], Loss: 28167.3398\n",
            "Epoch [40/1000], Loss: 32476.5137\n",
            "Epoch [40/1000], Loss: 29411.9785\n",
            "Epoch [40/1000], Loss: 26862.125\n",
            "Epoch [40/1000], Loss: 31389.8789\n",
            "Epoch [40/1000], Loss: 27491.7734\n",
            "Epoch [40/1000], Loss: 34284.7812\n",
            "Epoch [50/1000], Loss: 27169.877\n",
            "Epoch [50/1000], Loss: 32061.7461\n",
            "Epoch [50/1000], Loss: 34414.5859\n",
            "Epoch [50/1000], Loss: 24571.2188\n",
            "Epoch [50/1000], Loss: 26068.2051\n",
            "Epoch [50/1000], Loss: 26249.2773\n",
            "Epoch [50/1000], Loss: 36221.5586\n",
            "Epoch [50/1000], Loss: 22858.2266\n",
            "Epoch [60/1000], Loss: 29576.7422\n",
            "Epoch [60/1000], Loss: 29481.2148\n",
            "Epoch [60/1000], Loss: 27879.7578\n",
            "Epoch [60/1000], Loss: 28213.8398\n",
            "Epoch [60/1000], Loss: 27053.2402\n",
            "Epoch [60/1000], Loss: 31294.0898\n",
            "Epoch [60/1000], Loss: 32691.9551\n",
            "Epoch [60/1000], Loss: 29416.2773\n",
            "Epoch [70/1000], Loss: 31494.3867\n",
            "Epoch [70/1000], Loss: 29799.9609\n",
            "Epoch [70/1000], Loss: 30309.8945\n",
            "Epoch [70/1000], Loss: 31491.457\n",
            "Epoch [70/1000], Loss: 27346.9512\n",
            "Epoch [70/1000], Loss: 24826.1895\n",
            "Epoch [70/1000], Loss: 31270.8691\n",
            "Epoch [70/1000], Loss: 20734.3359\n",
            "Epoch [80/1000], Loss: 31582.2715\n",
            "Epoch [80/1000], Loss: 28610.125\n",
            "Epoch [80/1000], Loss: 22970.5801\n",
            "Epoch [80/1000], Loss: 31269.0488\n",
            "Epoch [80/1000], Loss: 27999.0977\n",
            "Epoch [80/1000], Loss: 34118.8906\n",
            "Epoch [80/1000], Loss: 28407.2539\n",
            "Epoch [80/1000], Loss: 44217.6367\n",
            "Epoch [90/1000], Loss: 30925.7891\n",
            "Epoch [90/1000], Loss: 24926.4414\n",
            "Epoch [90/1000], Loss: 31675.3691\n",
            "Epoch [90/1000], Loss: 25080.1895\n",
            "Epoch [90/1000], Loss: 38286.793\n",
            "Epoch [90/1000], Loss: 32673.4141\n",
            "Epoch [90/1000], Loss: 21789.5352\n",
            "Epoch [90/1000], Loss: 34652.875\n",
            "Epoch [100/1000], Loss: 32721.9941\n",
            "Epoch [100/1000], Loss: 24786.2402\n",
            "Epoch [100/1000], Loss: 25637.1523\n",
            "Epoch [100/1000], Loss: 30838.5801\n",
            "Epoch [100/1000], Loss: 28825.5078\n",
            "Epoch [100/1000], Loss: 32806.1406\n",
            "Epoch [100/1000], Loss: 30241.0176\n",
            "Epoch [100/1000], Loss: 23494.793\n",
            "Epoch [110/1000], Loss: 26474.9902\n",
            "Epoch [110/1000], Loss: 35726.293\n",
            "Epoch [110/1000], Loss: 33173.9453\n",
            "Epoch [110/1000], Loss: 36222.5078\n",
            "Epoch [110/1000], Loss: 23123.6523\n",
            "Epoch [110/1000], Loss: 24783.4043\n",
            "Epoch [110/1000], Loss: 26638.875\n",
            "Epoch [110/1000], Loss: 15888.2412\n",
            "Epoch [120/1000], Loss: 37271.0625\n",
            "Epoch [120/1000], Loss: 30671.8887\n",
            "Epoch [120/1000], Loss: 29999.7852\n",
            "Epoch [120/1000], Loss: 23899.4512\n",
            "Epoch [120/1000], Loss: 32170.0801\n",
            "Epoch [120/1000], Loss: 30745.2559\n",
            "Epoch [120/1000], Loss: 20330.9707\n",
            "Epoch [120/1000], Loss: 30679.6133\n",
            "Epoch [130/1000], Loss: 29765.7441\n",
            "Epoch [130/1000], Loss: 30228.1719\n",
            "Epoch [130/1000], Loss: 31152.334\n",
            "Epoch [130/1000], Loss: 25597.8887\n",
            "Epoch [130/1000], Loss: 27252.9785\n",
            "Epoch [130/1000], Loss: 29547.2598\n",
            "Epoch [130/1000], Loss: 31271.0352\n",
            "Epoch [130/1000], Loss: 32394.6523\n",
            "Epoch [140/1000], Loss: 30417.0625\n",
            "Epoch [140/1000], Loss: 33797.2734\n",
            "Epoch [140/1000], Loss: 26758.9941\n",
            "Epoch [140/1000], Loss: 31341.584\n",
            "Epoch [140/1000], Loss: 23535.7949\n",
            "Epoch [140/1000], Loss: 23316.2129\n",
            "Epoch [140/1000], Loss: 35232.0352\n",
            "Epoch [140/1000], Loss: 36538.3086\n",
            "Epoch [150/1000], Loss: 30307.3965\n",
            "Epoch [150/1000], Loss: 24134.459\n",
            "Epoch [150/1000], Loss: 29658.75\n",
            "Epoch [150/1000], Loss: 29660.7422\n",
            "Epoch [150/1000], Loss: 24836.7754\n",
            "Epoch [150/1000], Loss: 31090.3887\n",
            "Epoch [150/1000], Loss: 34569.1836\n",
            "Epoch [150/1000], Loss: 36065.9688\n",
            "Epoch [160/1000], Loss: 28087.4453\n",
            "Epoch [160/1000], Loss: 26892.5293\n",
            "Epoch [160/1000], Loss: 28324.8145\n",
            "Epoch [160/1000], Loss: 30561.125\n",
            "Epoch [160/1000], Loss: 28701.1152\n",
            "Epoch [160/1000], Loss: 29675.0449\n",
            "Epoch [160/1000], Loss: 32613.8594\n",
            "Epoch [160/1000], Loss: 23230.6641\n",
            "Epoch [170/1000], Loss: 29928.3027\n",
            "Epoch [170/1000], Loss: 27661.2637\n",
            "Epoch [170/1000], Loss: 28716.7148\n",
            "Epoch [170/1000], Loss: 32697.2051\n",
            "Epoch [170/1000], Loss: 32579.3066\n",
            "Epoch [170/1000], Loss: 23534.2051\n",
            "Epoch [170/1000], Loss: 28189.5938\n",
            "Epoch [170/1000], Loss: 46228.8359\n",
            "Epoch [180/1000], Loss: 25553.6699\n",
            "Epoch [180/1000], Loss: 29921.6484\n",
            "Epoch [180/1000], Loss: 36392.0625\n",
            "Epoch [180/1000], Loss: 28152.0391\n",
            "Epoch [180/1000], Loss: 29940.2402\n",
            "Epoch [180/1000], Loss: 27206.4551\n",
            "Epoch [180/1000], Loss: 27860.0078\n",
            "Epoch [180/1000], Loss: 14721.6709\n",
            "Epoch [190/1000], Loss: 27437.5\n",
            "Epoch [190/1000], Loss: 28522.4609\n",
            "Epoch [190/1000], Loss: 29418.7617\n",
            "Epoch [190/1000], Loss: 32391.6621\n",
            "Epoch [190/1000], Loss: 29480.8242\n",
            "Epoch [190/1000], Loss: 24740.2188\n",
            "Epoch [190/1000], Loss: 32614.1289\n",
            "Epoch [190/1000], Loss: 18900.5781\n",
            "Epoch [200/1000], Loss: 29547.2637\n",
            "Epoch [200/1000], Loss: 20742.3672\n",
            "Epoch [200/1000], Loss: 23500.6895\n",
            "Epoch [200/1000], Loss: 35195.7383\n",
            "Epoch [200/1000], Loss: 31605.0684\n",
            "Epoch [200/1000], Loss: 30394.6777\n",
            "Epoch [200/1000], Loss: 33892.8047\n",
            "Epoch [200/1000], Loss: 11529.3428\n",
            "Epoch [210/1000], Loss: 29576.1641\n",
            "Epoch [210/1000], Loss: 25147.0938\n",
            "Epoch [210/1000], Loss: 27534.877\n",
            "Epoch [210/1000], Loss: 29917.9199\n",
            "Epoch [210/1000], Loss: 32116.7695\n",
            "Epoch [210/1000], Loss: 29240.5371\n",
            "Epoch [210/1000], Loss: 31308.1074\n",
            "Epoch [210/1000], Loss: 9292.5977\n",
            "Epoch [220/1000], Loss: 31129.6211\n",
            "Epoch [220/1000], Loss: 23795.834\n",
            "Epoch [220/1000], Loss: 29766.7051\n",
            "Epoch [220/1000], Loss: 27831.7227\n",
            "Epoch [220/1000], Loss: 33208.8398\n",
            "Epoch [220/1000], Loss: 27147.1641\n",
            "Epoch [220/1000], Loss: 29532.5078\n",
            "Epoch [220/1000], Loss: 46962.3672\n",
            "Epoch [230/1000], Loss: 32528.1836\n",
            "Epoch [230/1000], Loss: 27143.7188\n",
            "Epoch [230/1000], Loss: 35218.5156\n",
            "Epoch [230/1000], Loss: 27521.7344\n",
            "Epoch [230/1000], Loss: 25176.5449\n",
            "Epoch [230/1000], Loss: 29517.1973\n",
            "Epoch [230/1000], Loss: 27098.1699\n",
            "Epoch [230/1000], Loss: 14298.291\n",
            "Epoch [240/1000], Loss: 29767.2637\n",
            "Epoch [240/1000], Loss: 26986.8145\n",
            "Epoch [240/1000], Loss: 24550.1641\n",
            "Epoch [240/1000], Loss: 27261.7051\n",
            "Epoch [240/1000], Loss: 23346.2461\n",
            "Epoch [240/1000], Loss: 35104.4961\n",
            "Epoch [240/1000], Loss: 33792.1406\n",
            "Epoch [240/1000], Loss: 68087.0156\n",
            "Epoch [250/1000], Loss: 25067.5293\n",
            "Epoch [250/1000], Loss: 29148.5137\n",
            "Epoch [250/1000], Loss: 26802.0527\n",
            "Epoch [250/1000], Loss: 30413.3945\n",
            "Epoch [250/1000], Loss: 26991.5293\n",
            "Epoch [250/1000], Loss: 28785.7539\n",
            "Epoch [250/1000], Loss: 36276.6094\n",
            "Epoch [250/1000], Loss: 20649.3574\n",
            "Epoch [260/1000], Loss: 30453.1094\n",
            "Epoch [260/1000], Loss: 23612.5488\n",
            "Epoch [260/1000], Loss: 26095.0703\n",
            "Epoch [260/1000], Loss: 36848.2383\n",
            "Epoch [260/1000], Loss: 30268.6348\n",
            "Epoch [260/1000], Loss: 30906.0352\n",
            "Epoch [260/1000], Loss: 25066.0078\n",
            "Epoch [260/1000], Loss: 21751.6211\n",
            "Epoch [270/1000], Loss: 32492.6836\n",
            "Epoch [270/1000], Loss: 28422.3867\n",
            "Epoch [270/1000], Loss: 27466.0488\n",
            "Epoch [270/1000], Loss: 23490.6504\n",
            "Epoch [270/1000], Loss: 24860.7539\n",
            "Epoch [270/1000], Loss: 35362.5781\n",
            "Epoch [270/1000], Loss: 29733.0898\n",
            "Epoch [270/1000], Loss: 42607.0312\n",
            "Epoch [280/1000], Loss: 33602.457\n",
            "Epoch [280/1000], Loss: 33704.1055\n",
            "Epoch [280/1000], Loss: 24193.7129\n",
            "Epoch [280/1000], Loss: 31627.4277\n",
            "Epoch [280/1000], Loss: 25632.375\n",
            "Epoch [280/1000], Loss: 24845.1738\n",
            "Epoch [280/1000], Loss: 25877.084\n",
            "Epoch [280/1000], Loss: 78861.8984\n",
            "Epoch [290/1000], Loss: 30143.0234\n",
            "Epoch [290/1000], Loss: 29247.127\n",
            "Epoch [290/1000], Loss: 29805.2246\n",
            "Epoch [290/1000], Loss: 26529.1348\n",
            "Epoch [290/1000], Loss: 29268.6953\n",
            "Epoch [290/1000], Loss: 31855.5\n",
            "Epoch [290/1000], Loss: 25605.7188\n",
            "Epoch [290/1000], Loss: 26505.4824\n",
            "Epoch [300/1000], Loss: 34931.5312\n",
            "Epoch [300/1000], Loss: 31785.1367\n",
            "Epoch [300/1000], Loss: 32052.4961\n",
            "Epoch [300/1000], Loss: 26712.8262\n",
            "Epoch [300/1000], Loss: 22830.1914\n",
            "Epoch [300/1000], Loss: 33403.5781\n",
            "Epoch [300/1000], Loss: 21646.3594\n",
            "Epoch [300/1000], Loss: 8552.8105\n",
            "Epoch [310/1000], Loss: 28686.6543\n",
            "Epoch [310/1000], Loss: 30741.5645\n",
            "Epoch [310/1000], Loss: 31125.1016\n",
            "Epoch [310/1000], Loss: 32466.0996\n",
            "Epoch [310/1000], Loss: 26619.7539\n",
            "Epoch [310/1000], Loss: 30189.8398\n",
            "Epoch [310/1000], Loss: 21883.7754\n",
            "Epoch [310/1000], Loss: 33279.6172\n",
            "Epoch [320/1000], Loss: 30176.8086\n",
            "Epoch [320/1000], Loss: 26447.25\n",
            "Epoch [320/1000], Loss: 25299.8047\n",
            "Epoch [320/1000], Loss: 32549.5977\n",
            "Epoch [320/1000], Loss: 25950.9766\n",
            "Epoch [320/1000], Loss: 34788.125\n",
            "Epoch [320/1000], Loss: 27805.0996\n",
            "Epoch [320/1000], Loss: 8710.5273\n",
            "Epoch [330/1000], Loss: 29053.0859\n",
            "Epoch [330/1000], Loss: 27328.4336\n",
            "Epoch [330/1000], Loss: 27054.1738\n",
            "Epoch [330/1000], Loss: 30605.7285\n",
            "Epoch [330/1000], Loss: 27316.6348\n",
            "Epoch [330/1000], Loss: 29796.752\n",
            "Epoch [330/1000], Loss: 30508.2344\n",
            "Epoch [330/1000], Loss: 28550.1875\n",
            "Epoch [340/1000], Loss: 24392.9941\n",
            "Epoch [340/1000], Loss: 27562.2793\n",
            "Epoch [340/1000], Loss: 33251.7578\n",
            "Epoch [340/1000], Loss: 30825.1152\n",
            "Epoch [340/1000], Loss: 28470.5703\n",
            "Epoch [340/1000], Loss: 25215.4199\n",
            "Epoch [340/1000], Loss: 31821.1836\n",
            "Epoch [340/1000], Loss: 27849.5547\n",
            "Epoch [350/1000], Loss: 26861.5586\n",
            "Epoch [350/1000], Loss: 31619.3984\n",
            "Epoch [350/1000], Loss: 31183.3047\n",
            "Epoch [350/1000], Loss: 29367.0098\n",
            "Epoch [350/1000], Loss: 21783.6289\n",
            "Epoch [350/1000], Loss: 31801.0137\n",
            "Epoch [350/1000], Loss: 28538.1602\n",
            "Epoch [350/1000], Loss: 31519.959\n",
            "Epoch [360/1000], Loss: 23943.7344\n",
            "Epoch [360/1000], Loss: 26290.7715\n",
            "Epoch [360/1000], Loss: 31764.5273\n",
            "Epoch [360/1000], Loss: 28369.9238\n",
            "Epoch [360/1000], Loss: 31305.5586\n",
            "Epoch [360/1000], Loss: 32656.9746\n",
            "Epoch [360/1000], Loss: 27454.2637\n",
            "Epoch [360/1000], Loss: 18127.1855\n",
            "Epoch [370/1000], Loss: 24089.0938\n",
            "Epoch [370/1000], Loss: 26771.5645\n",
            "Epoch [370/1000], Loss: 27254.2402\n",
            "Epoch [370/1000], Loss: 28801.6973\n",
            "Epoch [370/1000], Loss: 32272.2012\n",
            "Epoch [370/1000], Loss: 28836.4297\n",
            "Epoch [370/1000], Loss: 31827.332\n",
            "Epoch [370/1000], Loss: 47567.1172\n",
            "Epoch [380/1000], Loss: 31665.7715\n",
            "Epoch [380/1000], Loss: 26348.4414\n",
            "Epoch [380/1000], Loss: 24860.9941\n",
            "Epoch [380/1000], Loss: 32549.6895\n",
            "Epoch [380/1000], Loss: 27919.4785\n",
            "Epoch [380/1000], Loss: 27181.0566\n",
            "Epoch [380/1000], Loss: 29845.7188\n",
            "Epoch [380/1000], Loss: 36163.2852\n",
            "Epoch [390/1000], Loss: 27061.3145\n",
            "Epoch [390/1000], Loss: 31527.0859\n",
            "Epoch [390/1000], Loss: 26202.5176\n",
            "Epoch [390/1000], Loss: 24947.5137\n",
            "Epoch [390/1000], Loss: 30786.4492\n",
            "Epoch [390/1000], Loss: 27157.002\n",
            "Epoch [390/1000], Loss: 32445.7051\n",
            "Epoch [390/1000], Loss: 37413.4297\n",
            "Epoch [400/1000], Loss: 27415.5\n",
            "Epoch [400/1000], Loss: 28126.0625\n",
            "Epoch [400/1000], Loss: 30508.3242\n",
            "Epoch [400/1000], Loss: 29664.4297\n",
            "Epoch [400/1000], Loss: 26463.9121\n",
            "Epoch [400/1000], Loss: 30323.334\n",
            "Epoch [400/1000], Loss: 28673.7637\n",
            "Epoch [400/1000], Loss: 17121.7812\n",
            "Epoch [410/1000], Loss: 22529.2402\n",
            "Epoch [410/1000], Loss: 23416.3848\n",
            "Epoch [410/1000], Loss: 34814.4766\n",
            "Epoch [410/1000], Loss: 29687.7734\n",
            "Epoch [410/1000], Loss: 30802.7344\n",
            "Epoch [410/1000], Loss: 28197.7637\n",
            "Epoch [410/1000], Loss: 28656.5039\n",
            "Epoch [410/1000], Loss: 65495.7461\n",
            "Epoch [420/1000], Loss: 36786.6016\n",
            "Epoch [420/1000], Loss: 25991.8398\n",
            "Epoch [420/1000], Loss: 30001.1191\n",
            "Epoch [420/1000], Loss: 26353.0898\n",
            "Epoch [420/1000], Loss: 23797.4688\n",
            "Epoch [420/1000], Loss: 31068.6445\n",
            "Epoch [420/1000], Loss: 26199.4141\n",
            "Epoch [420/1000], Loss: 27800.4141\n",
            "Epoch [430/1000], Loss: 28301.5645\n",
            "Epoch [430/1000], Loss: 36986.5156\n",
            "Epoch [430/1000], Loss: 32918.2305\n",
            "Epoch [430/1000], Loss: 22258.2852\n",
            "Epoch [430/1000], Loss: 24931.4199\n",
            "Epoch [430/1000], Loss: 25719.5352\n",
            "Epoch [430/1000], Loss: 27036.4297\n",
            "Epoch [430/1000], Loss: 59150.1094\n",
            "Epoch [440/1000], Loss: 25221.0312\n",
            "Epoch [440/1000], Loss: 29299.7891\n",
            "Epoch [440/1000], Loss: 36298.2773\n",
            "Epoch [440/1000], Loss: 26660.4902\n",
            "Epoch [440/1000], Loss: 29489.8574\n",
            "Epoch [440/1000], Loss: 29853.8438\n",
            "Epoch [440/1000], Loss: 21508.6816\n",
            "Epoch [440/1000], Loss: 53349.7109\n",
            "Epoch [450/1000], Loss: 32359.4688\n",
            "Epoch [450/1000], Loss: 32264.6035\n",
            "Epoch [450/1000], Loss: 32493.3574\n",
            "Epoch [450/1000], Loss: 26561.7363\n",
            "Epoch [450/1000], Loss: 24880.9746\n",
            "Epoch [450/1000], Loss: 23178.7949\n",
            "Epoch [450/1000], Loss: 28618.5\n",
            "Epoch [450/1000], Loss: 16830.834\n",
            "Epoch [460/1000], Loss: 28115.4277\n",
            "Epoch [460/1000], Loss: 33151.3008\n",
            "Epoch [460/1000], Loss: 27482.084\n",
            "Epoch [460/1000], Loss: 24800.8965\n",
            "Epoch [460/1000], Loss: 27739.4062\n",
            "Epoch [460/1000], Loss: 27284.8887\n",
            "Epoch [460/1000], Loss: 28819.7598\n",
            "Epoch [460/1000], Loss: 63438.625\n",
            "Epoch [470/1000], Loss: 28308.2988\n",
            "Epoch [470/1000], Loss: 28309.6953\n",
            "Epoch [470/1000], Loss: 29505.1602\n",
            "Epoch [470/1000], Loss: 31172.5215\n",
            "Epoch [470/1000], Loss: 23974.4824\n",
            "Epoch [470/1000], Loss: 31075.7969\n",
            "Epoch [470/1000], Loss: 27487.459\n",
            "Epoch [470/1000], Loss: 20000.5625\n",
            "Epoch [480/1000], Loss: 31417.6738\n",
            "Epoch [480/1000], Loss: 27359.2148\n",
            "Epoch [480/1000], Loss: 30376.2617\n",
            "Epoch [480/1000], Loss: 27469.4727\n",
            "Epoch [480/1000], Loss: 28556.8984\n",
            "Epoch [480/1000], Loss: 25170.0703\n",
            "Epoch [480/1000], Loss: 29264.5859\n",
            "Epoch [480/1000], Loss: 20887.4512\n",
            "Epoch [490/1000], Loss: 33628.7617\n",
            "Epoch [490/1000], Loss: 22903.377\n",
            "Epoch [490/1000], Loss: 27183.0371\n",
            "Epoch [490/1000], Loss: 29435.9199\n",
            "Epoch [490/1000], Loss: 23616.9414\n",
            "Epoch [490/1000], Loss: 31543.459\n",
            "Epoch [490/1000], Loss: 29281.0391\n",
            "Epoch [490/1000], Loss: 51822.3555\n",
            "Epoch [500/1000], Loss: 29823.1035\n",
            "Epoch [500/1000], Loss: 30542.4316\n",
            "Epoch [500/1000], Loss: 31987.6797\n",
            "Epoch [500/1000], Loss: 29175.0977\n",
            "Epoch [500/1000], Loss: 29445.127\n",
            "Epoch [500/1000], Loss: 25312.8613\n",
            "Epoch [500/1000], Loss: 21946.2852\n",
            "Epoch [500/1000], Loss: 38339.6719\n",
            "Epoch [510/1000], Loss: 26654.877\n",
            "Epoch [510/1000], Loss: 26930.9062\n",
            "Epoch [510/1000], Loss: 24922.0996\n",
            "Epoch [510/1000], Loss: 26970.4941\n",
            "Epoch [510/1000], Loss: 34437.6523\n",
            "Epoch [510/1000], Loss: 24381.3301\n",
            "Epoch [510/1000], Loss: 33634.0\n",
            "Epoch [510/1000], Loss: 40581.3828\n",
            "Epoch [520/1000], Loss: 25617.3301\n",
            "Epoch [520/1000], Loss: 29152.1094\n",
            "Epoch [520/1000], Loss: 27393.3789\n",
            "Epoch [520/1000], Loss: 29557.7598\n",
            "Epoch [520/1000], Loss: 27643.6094\n",
            "Epoch [520/1000], Loss: 22957.9219\n",
            "Epoch [520/1000], Loss: 35796.4102\n",
            "Epoch [520/1000], Loss: 34699.9141\n",
            "Epoch [530/1000], Loss: 33536.4375\n",
            "Epoch [530/1000], Loss: 25487.0391\n",
            "Epoch [530/1000], Loss: 22270.5371\n",
            "Epoch [530/1000], Loss: 29937.0273\n",
            "Epoch [530/1000], Loss: 29810.0938\n",
            "Epoch [530/1000], Loss: 29536.8496\n",
            "Epoch [530/1000], Loss: 27000.5703\n",
            "Epoch [530/1000], Loss: 40926.5547\n",
            "Epoch [540/1000], Loss: 28079.7148\n",
            "Epoch [540/1000], Loss: 28219.0664\n",
            "Epoch [540/1000], Loss: 28382.627\n",
            "Epoch [540/1000], Loss: 27741.6953\n",
            "Epoch [540/1000], Loss: 31424.3184\n",
            "Epoch [540/1000], Loss: 23171.8086\n",
            "Epoch [540/1000], Loss: 31588.1641\n",
            "Epoch [540/1000], Loss: 20974.8496\n",
            "Epoch [550/1000], Loss: 21730.1953\n",
            "Epoch [550/1000], Loss: 26688.0488\n",
            "Epoch [550/1000], Loss: 26755.502\n",
            "Epoch [550/1000], Loss: 28046.9395\n",
            "Epoch [550/1000], Loss: 31342.2148\n",
            "Epoch [550/1000], Loss: 30972.3262\n",
            "Epoch [550/1000], Loss: 32089.7344\n",
            "Epoch [550/1000], Loss: 34571.5\n",
            "Epoch [560/1000], Loss: 27798.4844\n",
            "Epoch [560/1000], Loss: 29089.6543\n",
            "Epoch [560/1000], Loss: 26791.6426\n",
            "Epoch [560/1000], Loss: 27128.6543\n",
            "Epoch [560/1000], Loss: 26354.1992\n",
            "Epoch [560/1000], Loss: 29435.3945\n",
            "Epoch [560/1000], Loss: 30760.1172\n",
            "Epoch [560/1000], Loss: 36219.5625\n",
            "Epoch [570/1000], Loss: 26353.2578\n",
            "Epoch [570/1000], Loss: 30435.9648\n",
            "Epoch [570/1000], Loss: 26680.3027\n",
            "Epoch [570/1000], Loss: 30651.4512\n",
            "Epoch [570/1000], Loss: 31418.5137\n",
            "Epoch [570/1000], Loss: 25631.502\n",
            "Epoch [570/1000], Loss: 27285.9277\n",
            "Epoch [570/1000], Loss: 15135.9512\n",
            "Epoch [580/1000], Loss: 26434.9746\n",
            "Epoch [580/1000], Loss: 29817.166\n",
            "Epoch [580/1000], Loss: 29093.6836\n",
            "Epoch [580/1000], Loss: 24295.4043\n",
            "Epoch [580/1000], Loss: 33858.875\n",
            "Epoch [580/1000], Loss: 28121.7949\n",
            "Epoch [580/1000], Loss: 26229.1992\n",
            "Epoch [580/1000], Loss: 22504.0508\n",
            "Epoch [590/1000], Loss: 35234.7383\n",
            "Epoch [590/1000], Loss: 27157.5645\n",
            "Epoch [590/1000], Loss: 28541.5898\n",
            "Epoch [590/1000], Loss: 25828.5547\n",
            "Epoch [590/1000], Loss: 30838.6426\n",
            "Epoch [590/1000], Loss: 24340.0625\n",
            "Epoch [590/1000], Loss: 26579.4141\n",
            "Epoch [590/1000], Loss: 8599.5625\n",
            "Epoch [600/1000], Loss: 29212.584\n",
            "Epoch [600/1000], Loss: 28573.9824\n",
            "Epoch [600/1000], Loss: 34053.4141\n",
            "Epoch [600/1000], Loss: 23961.834\n",
            "Epoch [600/1000], Loss: 26859.8516\n",
            "Epoch [600/1000], Loss: 26830.2051\n",
            "Epoch [600/1000], Loss: 25567.832\n",
            "Epoch [600/1000], Loss: 63557.5938\n",
            "Epoch [610/1000], Loss: 25547.8887\n",
            "Epoch [610/1000], Loss: 32369.0938\n",
            "Epoch [610/1000], Loss: 34604.0039\n",
            "Epoch [610/1000], Loss: 27534.6641\n",
            "Epoch [610/1000], Loss: 26865.3848\n",
            "Epoch [610/1000], Loss: 26943.6465\n",
            "Epoch [610/1000], Loss: 23407.2988\n",
            "Epoch [610/1000], Loss: 23868.2402\n",
            "Epoch [620/1000], Loss: 24641.6953\n",
            "Epoch [620/1000], Loss: 28122.7441\n",
            "Epoch [620/1000], Loss: 29903.7598\n",
            "Epoch [620/1000], Loss: 29095.9395\n",
            "Epoch [620/1000], Loss: 24689.7754\n",
            "Epoch [620/1000], Loss: 29348.6562\n",
            "Epoch [620/1000], Loss: 30333.334\n",
            "Epoch [620/1000], Loss: 40002.9219\n",
            "Epoch [630/1000], Loss: 24761.1602\n",
            "Epoch [630/1000], Loss: 31819.3652\n",
            "Epoch [630/1000], Loss: 30055.8789\n",
            "Epoch [630/1000], Loss: 28421.0762\n",
            "Epoch [630/1000], Loss: 26866.5645\n",
            "Epoch [630/1000], Loss: 30503.6094\n",
            "Epoch [630/1000], Loss: 24545.7969\n",
            "Epoch [630/1000], Loss: 23272.4102\n",
            "Epoch [640/1000], Loss: 24372.6094\n",
            "Epoch [640/1000], Loss: 30719.8184\n",
            "Epoch [640/1000], Loss: 27397.6797\n",
            "Epoch [640/1000], Loss: 31828.8945\n",
            "Epoch [640/1000], Loss: 29602.5645\n",
            "Epoch [640/1000], Loss: 29936.1094\n",
            "Epoch [640/1000], Loss: 23054.7148\n",
            "Epoch [640/1000], Loss: 21565.8242\n",
            "Epoch [650/1000], Loss: 29833.9609\n",
            "Epoch [650/1000], Loss: 25254.916\n",
            "Epoch [650/1000], Loss: 24783.1621\n",
            "Epoch [650/1000], Loss: 29419.959\n",
            "Epoch [650/1000], Loss: 29034.9336\n",
            "Epoch [650/1000], Loss: 32284.8516\n",
            "Epoch [650/1000], Loss: 25112.2852\n",
            "Epoch [650/1000], Loss: 38647.3242\n",
            "Epoch [660/1000], Loss: 35278.9375\n",
            "Epoch [660/1000], Loss: 31895.0234\n",
            "Epoch [660/1000], Loss: 22676.1191\n",
            "Epoch [660/1000], Loss: 25240.2695\n",
            "Epoch [660/1000], Loss: 27670.7949\n",
            "Epoch [660/1000], Loss: 23877.6543\n",
            "Epoch [660/1000], Loss: 30036.2617\n",
            "Epoch [660/1000], Loss: 20060.9629\n",
            "Epoch [670/1000], Loss: 24895.4648\n",
            "Epoch [670/1000], Loss: 29598.6152\n",
            "Epoch [670/1000], Loss: 31971.0352\n",
            "Epoch [670/1000], Loss: 28925.4453\n",
            "Epoch [670/1000], Loss: 25790.4551\n",
            "Epoch [670/1000], Loss: 30195.9863\n",
            "Epoch [670/1000], Loss: 25200.8594\n",
            "Epoch [670/1000], Loss: 18976.0703\n",
            "Epoch [680/1000], Loss: 34572.8711\n",
            "Epoch [680/1000], Loss: 28113.7949\n",
            "Epoch [680/1000], Loss: 24796.7988\n",
            "Epoch [680/1000], Loss: 27400.1699\n",
            "Epoch [680/1000], Loss: 30677.1895\n",
            "Epoch [680/1000], Loss: 24837.7988\n",
            "Epoch [680/1000], Loss: 24703.8203\n",
            "Epoch [680/1000], Loss: 40816.8086\n",
            "Epoch [690/1000], Loss: 22716.3652\n",
            "Epoch [690/1000], Loss: 28532.8691\n",
            "Epoch [690/1000], Loss: 28338.2363\n",
            "Epoch [690/1000], Loss: 30051.0488\n",
            "Epoch [690/1000], Loss: 27982.7188\n",
            "Epoch [690/1000], Loss: 26261.9277\n",
            "Epoch [690/1000], Loss: 31370.6641\n",
            "Epoch [690/1000], Loss: 35568.793\n",
            "Epoch [700/1000], Loss: 34654.9805\n",
            "Epoch [700/1000], Loss: 31646.8652\n",
            "Epoch [700/1000], Loss: 30665.8789\n",
            "Epoch [700/1000], Loss: 26764.1738\n",
            "Epoch [700/1000], Loss: 25518.3652\n",
            "Epoch [700/1000], Loss: 24834.2695\n",
            "Epoch [700/1000], Loss: 22526.7168\n",
            "Epoch [700/1000], Loss: 10176.3613\n",
            "Epoch [710/1000], Loss: 24738.332\n",
            "Epoch [710/1000], Loss: 19926.4453\n",
            "Epoch [710/1000], Loss: 29795.1445\n",
            "Epoch [710/1000], Loss: 31820.6816\n",
            "Epoch [710/1000], Loss: 31825.9785\n",
            "Epoch [710/1000], Loss: 27324.1387\n",
            "Epoch [710/1000], Loss: 30242.0625\n",
            "Epoch [710/1000], Loss: 23080.3574\n",
            "Epoch [720/1000], Loss: 25200.0664\n",
            "Epoch [720/1000], Loss: 27152.6738\n",
            "Epoch [720/1000], Loss: 28802.9844\n",
            "Epoch [720/1000], Loss: 29204.6777\n",
            "Epoch [720/1000], Loss: 30634.3242\n",
            "Epoch [720/1000], Loss: 27533.916\n",
            "Epoch [720/1000], Loss: 27451.8926\n",
            "Epoch [720/1000], Loss: 15205.3867\n",
            "Epoch [730/1000], Loss: 32806.2422\n",
            "Epoch [730/1000], Loss: 29490.0371\n",
            "Epoch [730/1000], Loss: 28784.3789\n",
            "Epoch [730/1000], Loss: 23006.2793\n",
            "Epoch [730/1000], Loss: 27331.5293\n",
            "Epoch [730/1000], Loss: 26543.4551\n",
            "Epoch [730/1000], Loss: 25861.2715\n",
            "Epoch [730/1000], Loss: 48462.1836\n",
            "Epoch [740/1000], Loss: 28560.0645\n",
            "Epoch [740/1000], Loss: 27623.9238\n",
            "Epoch [740/1000], Loss: 23729.7344\n",
            "Epoch [740/1000], Loss: 32987.1953\n",
            "Epoch [740/1000], Loss: 30819.7695\n",
            "Epoch [740/1000], Loss: 26219.7871\n",
            "Epoch [740/1000], Loss: 24993.6426\n",
            "Epoch [740/1000], Loss: 27207.6309\n",
            "Epoch [750/1000], Loss: 28290.4062\n",
            "Epoch [750/1000], Loss: 30275.875\n",
            "Epoch [750/1000], Loss: 16881.2793\n",
            "Epoch [750/1000], Loss: 27480.6484\n",
            "Epoch [750/1000], Loss: 28964.6953\n",
            "Epoch [750/1000], Loss: 31725.375\n",
            "Epoch [750/1000], Loss: 30302.1797\n",
            "Epoch [750/1000], Loss: 41327.5859\n",
            "Epoch [760/1000], Loss: 32859.1445\n",
            "Epoch [760/1000], Loss: 20512.5664\n",
            "Epoch [760/1000], Loss: 28107.3789\n",
            "Epoch [760/1000], Loss: 32982.3359\n",
            "Epoch [760/1000], Loss: 26677.1191\n",
            "Epoch [760/1000], Loss: 25414.834\n",
            "Epoch [760/1000], Loss: 28900.9941\n",
            "Epoch [760/1000], Loss: 13054.3467\n",
            "Epoch [770/1000], Loss: 27147.75\n",
            "Epoch [770/1000], Loss: 24805.0879\n",
            "Epoch [770/1000], Loss: 31661.9727\n",
            "Epoch [770/1000], Loss: 25216.7988\n",
            "Epoch [770/1000], Loss: 27679.502\n",
            "Epoch [770/1000], Loss: 33604.4609\n",
            "Epoch [770/1000], Loss: 25333.0918\n",
            "Epoch [770/1000], Loss: 10457.5176\n",
            "Epoch [780/1000], Loss: 27025.5098\n",
            "Epoch [780/1000], Loss: 25961.834\n",
            "Epoch [780/1000], Loss: 26410.084\n",
            "Epoch [780/1000], Loss: 33335.4531\n",
            "Epoch [780/1000], Loss: 25858.0449\n",
            "Epoch [780/1000], Loss: 28843.6602\n",
            "Epoch [780/1000], Loss: 27052.5137\n",
            "Epoch [780/1000], Loss: 23750.8281\n",
            "Epoch [790/1000], Loss: 27006.5664\n",
            "Epoch [790/1000], Loss: 33539.3008\n",
            "Epoch [790/1000], Loss: 25024.2891\n",
            "Epoch [790/1000], Loss: 23538.875\n",
            "Epoch [790/1000], Loss: 30071.1348\n",
            "Epoch [790/1000], Loss: 32154.8848\n",
            "Epoch [790/1000], Loss: 23316.2344\n",
            "Epoch [790/1000], Loss: 18287.9922\n",
            "Epoch [800/1000], Loss: 29669.7422\n",
            "Epoch [800/1000], Loss: 27179.834\n",
            "Epoch [800/1000], Loss: 29847.7246\n",
            "Epoch [800/1000], Loss: 29965.5742\n",
            "Epoch [800/1000], Loss: 24806.5801\n",
            "Epoch [800/1000], Loss: 26273.7793\n",
            "Epoch [800/1000], Loss: 27349.7637\n",
            "Epoch [800/1000], Loss: 8226.9707\n",
            "Epoch [810/1000], Loss: 24706.2285\n",
            "Epoch [810/1000], Loss: 30293.4648\n",
            "Epoch [810/1000], Loss: 21435.8223\n",
            "Epoch [810/1000], Loss: 32186.1387\n",
            "Epoch [810/1000], Loss: 24540.0586\n",
            "Epoch [810/1000], Loss: 29713.3945\n",
            "Epoch [810/1000], Loss: 29140.6367\n",
            "Epoch [810/1000], Loss: 56764.8242\n",
            "Epoch [820/1000], Loss: 30047.1172\n",
            "Epoch [820/1000], Loss: 27367.8965\n",
            "Epoch [820/1000], Loss: 23750.3047\n",
            "Epoch [820/1000], Loss: 32187.3477\n",
            "Epoch [820/1000], Loss: 24570.5664\n",
            "Epoch [820/1000], Loss: 27276.8145\n",
            "Epoch [820/1000], Loss: 28089.1328\n",
            "Epoch [820/1000], Loss: 32796.125\n",
            "Epoch [830/1000], Loss: 29169.5195\n",
            "Epoch [830/1000], Loss: 31166.7168\n",
            "Epoch [830/1000], Loss: 31564.3887\n",
            "Epoch [830/1000], Loss: 33955.9648\n",
            "Epoch [830/1000], Loss: 23889.959\n",
            "Epoch [830/1000], Loss: 20401.252\n",
            "Epoch [830/1000], Loss: 24280.0137\n",
            "Epoch [830/1000], Loss: 11028.5859\n",
            "Epoch [840/1000], Loss: 28521.2266\n",
            "Epoch [840/1000], Loss: 24572.834\n",
            "Epoch [840/1000], Loss: 22276.7305\n",
            "Epoch [840/1000], Loss: 26373.3574\n",
            "Epoch [840/1000], Loss: 30096.4414\n",
            "Epoch [840/1000], Loss: 33081.2227\n",
            "Epoch [840/1000], Loss: 27655.8984\n",
            "Epoch [840/1000], Loss: 39143.043\n",
            "Epoch [850/1000], Loss: 31924.9785\n",
            "Epoch [850/1000], Loss: 25506.5918\n",
            "Epoch [850/1000], Loss: 28784.2441\n",
            "Epoch [850/1000], Loss: 26392.7344\n",
            "Epoch [850/1000], Loss: 26688.7285\n",
            "Epoch [850/1000], Loss: 21988.3145\n",
            "Epoch [850/1000], Loss: 30914.3145\n",
            "Epoch [850/1000], Loss: 42739.4297\n",
            "Epoch [860/1000], Loss: 33186.0\n",
            "Epoch [860/1000], Loss: 22760.2598\n",
            "Epoch [860/1000], Loss: 30927.9844\n",
            "Epoch [860/1000], Loss: 23615.1973\n",
            "Epoch [860/1000], Loss: 29207.0723\n",
            "Epoch [860/1000], Loss: 22117.2871\n",
            "Epoch [860/1000], Loss: 31733.1699\n",
            "Epoch [860/1000], Loss: 17543.6152\n",
            "Epoch [870/1000], Loss: 27091.5996\n",
            "Epoch [870/1000], Loss: 30995.1191\n",
            "Epoch [870/1000], Loss: 24631.957\n",
            "Epoch [870/1000], Loss: 24359.625\n",
            "Epoch [870/1000], Loss: 30116.457\n",
            "Epoch [870/1000], Loss: 27317.7188\n",
            "Epoch [870/1000], Loss: 29236.0449\n",
            "Epoch [870/1000], Loss: 11469.6865\n",
            "Epoch [880/1000], Loss: 22512.2188\n",
            "Epoch [880/1000], Loss: 28368.582\n",
            "Epoch [880/1000], Loss: 20827.4941\n",
            "Epoch [880/1000], Loss: 27934.0137\n",
            "Epoch [880/1000], Loss: 29553.0078\n",
            "Epoch [880/1000], Loss: 29952.0293\n",
            "Epoch [880/1000], Loss: 33752.5117\n",
            "Epoch [880/1000], Loss: 22928.1758\n",
            "Epoch [890/1000], Loss: 28729.3301\n",
            "Epoch [890/1000], Loss: 28318.6191\n",
            "Epoch [890/1000], Loss: 28702.334\n",
            "Epoch [890/1000], Loss: 27737.1777\n",
            "Epoch [890/1000], Loss: 27871.209\n",
            "Epoch [890/1000], Loss: 30371.7539\n",
            "Epoch [890/1000], Loss: 21079.957\n",
            "Epoch [890/1000], Loss: 21748.8047\n",
            "Epoch [900/1000], Loss: 29049.0449\n",
            "Epoch [900/1000], Loss: 26700.9863\n",
            "Epoch [900/1000], Loss: 30039.3047\n",
            "Epoch [900/1000], Loss: 28394.9219\n",
            "Epoch [900/1000], Loss: 27356.0293\n",
            "Epoch [900/1000], Loss: 23340.5254\n",
            "Epoch [900/1000], Loss: 28013.5352\n",
            "Epoch [900/1000], Loss: 17611.8477\n",
            "Epoch [910/1000], Loss: 20935.0703\n",
            "Epoch [910/1000], Loss: 25892.3574\n",
            "Epoch [910/1000], Loss: 27817.5938\n",
            "Epoch [910/1000], Loss: 30291.0137\n",
            "Epoch [910/1000], Loss: 32323.5293\n",
            "Epoch [910/1000], Loss: 30586.2109\n",
            "Epoch [910/1000], Loss: 25527.9902\n",
            "Epoch [910/1000], Loss: 6867.9844\n",
            "Epoch [920/1000], Loss: 23216.7852\n",
            "Epoch [920/1000], Loss: 25489.5195\n",
            "Epoch [920/1000], Loss: 25448.4043\n",
            "Epoch [920/1000], Loss: 30421.0371\n",
            "Epoch [920/1000], Loss: 28063.832\n",
            "Epoch [920/1000], Loss: 31338.7598\n",
            "Epoch [920/1000], Loss: 28151.5664\n",
            "Epoch [920/1000], Loss: 24898.2305\n",
            "Epoch [930/1000], Loss: 27448.6973\n",
            "Epoch [930/1000], Loss: 21671.4043\n",
            "Epoch [930/1000], Loss: 32910.3477\n",
            "Epoch [930/1000], Loss: 31826.2793\n",
            "Epoch [930/1000], Loss: 22822.2539\n",
            "Epoch [930/1000], Loss: 24612.4219\n",
            "Epoch [930/1000], Loss: 29711.502\n",
            "Epoch [930/1000], Loss: 41026.6289\n",
            "Epoch [940/1000], Loss: 27563.0527\n",
            "Epoch [940/1000], Loss: 33023.1133\n",
            "Epoch [940/1000], Loss: 28553.8945\n",
            "Epoch [940/1000], Loss: 28123.3789\n",
            "Epoch [940/1000], Loss: 22847.8262\n",
            "Epoch [940/1000], Loss: 25998.9941\n",
            "Epoch [940/1000], Loss: 25519.2793\n",
            "Epoch [940/1000], Loss: 27816.9121\n",
            "Epoch [950/1000], Loss: 26763.2422\n",
            "Epoch [950/1000], Loss: 22615.084\n",
            "Epoch [950/1000], Loss: 27719.4668\n",
            "Epoch [950/1000], Loss: 28758.8145\n",
            "Epoch [950/1000], Loss: 26226.4746\n",
            "Epoch [950/1000], Loss: 26077.7793\n",
            "Epoch [950/1000], Loss: 32478.6562\n",
            "Epoch [950/1000], Loss: 41611.3203\n",
            "Epoch [960/1000], Loss: 33134.5234\n",
            "Epoch [960/1000], Loss: 26533.4551\n",
            "Epoch [960/1000], Loss: 29227.9824\n",
            "Epoch [960/1000], Loss: 25963.9199\n",
            "Epoch [960/1000], Loss: 32958.0234\n",
            "Epoch [960/1000], Loss: 25302.4336\n",
            "Epoch [960/1000], Loss: 17670.7988\n",
            "Epoch [960/1000], Loss: 36386.5273\n",
            "Epoch [970/1000], Loss: 30250.0215\n",
            "Epoch [970/1000], Loss: 22289.377\n",
            "Epoch [970/1000], Loss: 33454.2109\n",
            "Epoch [970/1000], Loss: 28384.6152\n",
            "Epoch [970/1000], Loss: 24666.2852\n",
            "Epoch [970/1000], Loss: 21639.8848\n",
            "Epoch [970/1000], Loss: 30198.9648\n",
            "Epoch [970/1000], Loss: 32121.5938\n",
            "Epoch [980/1000], Loss: 31731.4043\n",
            "Epoch [980/1000], Loss: 26986.3398\n",
            "Epoch [980/1000], Loss: 28743.7949\n",
            "Epoch [980/1000], Loss: 26618.3262\n",
            "Epoch [980/1000], Loss: 20530.8379\n",
            "Epoch [980/1000], Loss: 24936.3398\n",
            "Epoch [980/1000], Loss: 29323.2402\n",
            "Epoch [980/1000], Loss: 63003.9805\n",
            "Epoch [990/1000], Loss: 23856.457\n",
            "Epoch [990/1000], Loss: 29680.6348\n",
            "Epoch [990/1000], Loss: 26541.207\n",
            "Epoch [990/1000], Loss: 23142.1289\n",
            "Epoch [990/1000], Loss: 26853.1289\n",
            "Epoch [990/1000], Loss: 34259.6758\n",
            "Epoch [990/1000], Loss: 26211.2441\n",
            "Epoch [990/1000], Loss: 32360.1777\n",
            "Epoch [1000/1000], Loss: 27126.002\n",
            "Epoch [1000/1000], Loss: 28396.2402\n",
            "Epoch [1000/1000], Loss: 25367.3301\n",
            "Epoch [1000/1000], Loss: 21737.7988\n",
            "Epoch [1000/1000], Loss: 31670.8535\n",
            "Epoch [1000/1000], Loss: 28955.7871\n",
            "Epoch [1000/1000], Loss: 26836.6484\n",
            "Epoch [1000/1000], Loss: 37214.5742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation (example)\n",
        "model.eval() # testing mode\n",
        "mse_values = [] # collect the MSE scores\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs) # predict the test data\n",
        "\n",
        "        # Calculate Mean Squared Error\n",
        "        mse = criterion(outputs, targets) # calcualte mse for the batch\n",
        "        mse_values.append(mse.item()) # add to the list of MSE values\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse = np.mean(mse_values)\n",
        "print(f\"Average MSE on test set: {avg_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzA1dpNXBLv2",
        "outputId": "713cedfa-2727-4ae5-f085-187441b092c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set: 23857.84765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predictions.extend(outputs.cpu().numpy())\n",
        "        actuals.extend(targets.cpu().numpy())\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame({'Predicted': np.array(predictions).flatten(), 'Actual': np.array(actuals).flatten()})\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9ziYp-uPBPav",
        "outputId": "534ff990-8399-462d-97f8-d058a229735b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Predicted  Actual\n",
              "0    8.259681   219.0\n",
              "1    8.259681    70.0\n",
              "2    8.259681   202.0\n",
              "3    8.259681   230.0\n",
              "4    8.259681   111.0\n",
              "..        ...     ...\n",
              "84   8.259681   153.0\n",
              "85   8.259681    98.0\n",
              "86   8.259681    37.0\n",
              "87   8.259681    63.0\n",
              "88   8.259681   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beec384d-aa9e-4148-9b42-c1f752b4e195\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>8.259681</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beec384d-aa9e-4148-9b42-c1f752b4e195')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-beec384d-aa9e-4148-9b42-c1f752b4e195 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-beec384d-aa9e-4148-9b42-c1f752b4e195');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1b05114f-3533-4a88-ae19-842738ae69fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b05114f-3533-4a88-ae19-842738ae69fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1b05114f-3533-4a88-ae19-842738ae69fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5376c511-f46f-4b42-84e3-1f941e977758\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5376c511-f46f-4b42-84e3-1f941e977758 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8.25968074798584\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class DiabetesModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModel, self).__init__()\n",
        "        # we'll set up the layers as a sequence using nn.Sequential\n",
        "        self.layers = nn.Sequential(\n",
        "\n",
        "            # first layer will be a linear layer that has 10x neurons\n",
        "            # (10x sets of linear regression)\n",
        "            # the layer takes the 10 features as input (i.e. 10, 10)\n",
        "            nn.Linear(10, 10),\n",
        "\n",
        "            nn.ReLU(), # ReLU activation\n",
        "\n",
        "            # second linear layer again has 5 neurons\n",
        "            # this time taking the input as the output of the last layer\n",
        "            # (which had 10x neurons)\n",
        "            nn.Linear(10, 5),\n",
        "\n",
        "            nn.ReLU(), # ReLU again\n",
        "\n",
        "            # third linear layer again has 5 neurons\n",
        "            # this time taking the input as the output of the last layer\n",
        "            # (which had 5x neurons)\n",
        "            nn.Linear(5, 5),\n",
        "\n",
        "            nn.ReLU(), # ReLU again\n",
        "            # last linear layer takes the output from the previous 5 neurons\n",
        "            # this time its a single output with no activation\n",
        "            # i.e. this is the predicitons (regression)\n",
        "            nn.Linear(5, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x) # pass the data through the layers"
      ],
      "metadata": {
        "id": "4tZVlEnpBaoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = DiabetesModel()\n",
        "criterion = nn.MSELoss() # MSE loss function\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "cFoX5wvQCWHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop (example - you'll likely want to add more epochs)\n",
        "epochs = 100 # 100 epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # use the train_loader to pass the inputs (x) and targets (y)\n",
        "  for inputs, targets in train_loader:\n",
        "    # pass to the GPU (hopefully)\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # pass model to GPU as well\n",
        "    model.to(device)\n",
        "\n",
        "    model.train() # put the model object in train mode\n",
        "    optimiser.zero_grad() # reset the gradiants\n",
        "    outputs = model(inputs) # create outputs\n",
        "    loss = criterion(outputs, targets) # compare with Y to get loss\n",
        "    loss.backward() # backpropogate the loss (next week)\n",
        "    optimiser.step() # # update the parameters based on this round of training\n",
        "\n",
        "  # every 10 steps we will print out the current loss\n",
        "    if (epoch+1) % 10 == 0: # modular arithmetic\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {round(loss.item(), 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAzHOC9BCauL",
        "outputId": "9edd1c15-73b7-4a34-c92f-62cba9908620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 27587.9844\n",
            "Epoch [10/100], Loss: 29509.875\n",
            "Epoch [10/100], Loss: 29669.1719\n",
            "Epoch [10/100], Loss: 27868.9219\n",
            "Epoch [10/100], Loss: 32745.6035\n",
            "Epoch [10/100], Loss: 28294.875\n",
            "Epoch [10/100], Loss: 30964.8418\n",
            "Epoch [10/100], Loss: 35087.8359\n",
            "Epoch [20/100], Loss: 25198.8672\n",
            "Epoch [20/100], Loss: 27683.1777\n",
            "Epoch [20/100], Loss: 30560.332\n",
            "Epoch [20/100], Loss: 27890.6191\n",
            "Epoch [20/100], Loss: 29574.1602\n",
            "Epoch [20/100], Loss: 27401.7051\n",
            "Epoch [20/100], Loss: 38700.2109\n",
            "Epoch [20/100], Loss: 17974.4277\n",
            "Epoch [30/100], Loss: 28592.0\n",
            "Epoch [30/100], Loss: 29179.5039\n",
            "Epoch [30/100], Loss: 29955.1621\n",
            "Epoch [30/100], Loss: 30785.6816\n",
            "Epoch [30/100], Loss: 33234.1836\n",
            "Epoch [30/100], Loss: 27455.7676\n",
            "Epoch [30/100], Loss: 25441.2324\n",
            "Epoch [30/100], Loss: 31973.3086\n",
            "Epoch [40/100], Loss: 27739.8984\n",
            "Epoch [40/100], Loss: 30664.7734\n",
            "Epoch [40/100], Loss: 32779.7305\n",
            "Epoch [40/100], Loss: 27103.1699\n",
            "Epoch [40/100], Loss: 31002.5586\n",
            "Epoch [40/100], Loss: 24795.8574\n",
            "Epoch [40/100], Loss: 27361.0488\n",
            "Epoch [40/100], Loss: 30234.7969\n",
            "Epoch [50/100], Loss: 25248.3887\n",
            "Epoch [50/100], Loss: 30775.9238\n",
            "Epoch [50/100], Loss: 25146.1523\n",
            "Epoch [50/100], Loss: 25215.0137\n",
            "Epoch [50/100], Loss: 26581.5449\n",
            "Epoch [50/100], Loss: 32458.6035\n",
            "Epoch [50/100], Loss: 29821.0547\n",
            "Epoch [50/100], Loss: 29213.8828\n",
            "Epoch [60/100], Loss: 27535.1445\n",
            "Epoch [60/100], Loss: 26387.2051\n",
            "Epoch [60/100], Loss: 20447.1797\n",
            "Epoch [60/100], Loss: 32678.5195\n",
            "Epoch [60/100], Loss: 26473.7188\n",
            "Epoch [60/100], Loss: 19161.9688\n",
            "Epoch [60/100], Loss: 32037.5664\n",
            "Epoch [60/100], Loss: 28413.5898\n",
            "Epoch [70/100], Loss: 21300.7852\n",
            "Epoch [70/100], Loss: 24447.5547\n",
            "Epoch [70/100], Loss: 23521.791\n",
            "Epoch [70/100], Loss: 28389.2285\n",
            "Epoch [70/100], Loss: 23135.502\n",
            "Epoch [70/100], Loss: 26031.9121\n",
            "Epoch [70/100], Loss: 21760.1348\n",
            "Epoch [70/100], Loss: 41633.7109\n",
            "Epoch [80/100], Loss: 21634.8086\n",
            "Epoch [80/100], Loss: 23791.6426\n",
            "Epoch [80/100], Loss: 16124.085\n",
            "Epoch [80/100], Loss: 19285.3164\n",
            "Epoch [80/100], Loss: 19249.2637\n",
            "Epoch [80/100], Loss: 21055.6836\n",
            "Epoch [80/100], Loss: 26789.6895\n",
            "Epoch [80/100], Loss: 30567.7617\n",
            "Epoch [90/100], Loss: 17642.8125\n",
            "Epoch [90/100], Loss: 18227.9414\n",
            "Epoch [90/100], Loss: 15593.043\n",
            "Epoch [90/100], Loss: 19466.0059\n",
            "Epoch [90/100], Loss: 15408.1396\n",
            "Epoch [90/100], Loss: 19350.8516\n",
            "Epoch [90/100], Loss: 19115.7891\n",
            "Epoch [90/100], Loss: 4900.5381\n",
            "Epoch [100/100], Loss: 16005.0693\n",
            "Epoch [100/100], Loss: 11289.8926\n",
            "Epoch [100/100], Loss: 14056.126\n",
            "Epoch [100/100], Loss: 17119.5391\n",
            "Epoch [100/100], Loss: 14091.3135\n",
            "Epoch [100/100], Loss: 10921.7207\n",
            "Epoch [100/100], Loss: 11365.6875\n",
            "Epoch [100/100], Loss: 56987.1641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation (example)\n",
        "model.eval() # testing mode\n",
        "mse_values = [] # collect the MSE scores\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs) # predict the test data\n",
        "\n",
        "        # Calculate Mean Squared Error\n",
        "        mse = criterion(outputs, targets) # calcualte mse for the batch\n",
        "        mse_values.append(mse.item()) # add to the list of MSE values\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse = np.mean(mse_values)\n",
        "print(f\"Average MSE on test set: {avg_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwflE490CfXU",
        "outputId": "98909e17-9333-4f61-91fd-d6fd8bd570a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set: 11608.13916015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predictions.extend(outputs.cpu().numpy())\n",
        "        actuals.extend(targets.cpu().numpy())\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame({'Predicted': np.array(predictions).flatten(), 'Actual': np.array(actuals).flatten()})\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "k4GT429FCmwv",
        "outputId": "cf8a5795-7396-4049-99db-782684680c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Predicted  Actual\n",
              "0   65.936378   219.0\n",
              "1   63.171467    70.0\n",
              "2   64.795486   202.0\n",
              "3   83.325867   230.0\n",
              "4   62.982182   111.0\n",
              "..        ...     ...\n",
              "84  55.986366   153.0\n",
              "85  51.369907    98.0\n",
              "86  46.257824    37.0\n",
              "87  48.028160    63.0\n",
              "88  58.168217   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-924c9a6b-6783-4c8a-be45-17e59b795ba7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65.936378</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63.171467</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.795486</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83.325867</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62.982182</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>55.986366</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>51.369907</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>46.257824</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>48.028160</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>58.168217</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-924c9a6b-6783-4c8a-be45-17e59b795ba7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-924c9a6b-6783-4c8a-be45-17e59b795ba7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-924c9a6b-6783-4c8a-be45-17e59b795ba7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4befd0f6-5624-4bff-a1d3-007b327228d8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4befd0f6-5624-4bff-a1d3-007b327228d8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4befd0f6-5624-4bff-a1d3-007b327228d8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_96ce89c8-01af-4425-8c73-76614765482a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_96ce89c8-01af-4425-8c73-76614765482a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          64.28201293945312,\n          55.58487319946289,\n          65.7846908569336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0,\n          61.0,\n          252.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}